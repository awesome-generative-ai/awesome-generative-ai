{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Introduction to Generative AI with HuggingFace\n",
    "\n",
    "Welcome to your first homework assignment on Generative AI! In this notebook, you'll explore various aspects of GenAI using HuggingFace tools and models. You'll work with text generation, translation, image generation, and audio processing.\n",
    "\n",
    "## Objectives:\n",
    "1. Set up the necessary libraries and environment\n",
    "2. Experiment with text generation using GPT-2\n",
    "3. Perform text translation\n",
    "4. Generate images using Stable Diffusion\n",
    "5. Work with audio generation and transcription\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's install the necessary libraries and import them. Run the following cells to set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers diffusers torch pydub TTS openai-whisper accelerate numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "from TTS.api import TTS\n",
    "import whisper\n",
    "\n",
    "USE_CUDA = True\n",
    "device = \"cuda\" if USE_CUDA and torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Generation with GPT-2\n",
    "\n",
    "Let's start by generating text using the GPT-2 model. You'll create a function to generate text based on a given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50):\n",
    "    model_name = \"gpt2-medium\"\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=max_length, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test the function\n",
    "prompt = \"Once upon a time in a land far, far away\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Creative Writing\n",
    "Generate a short story using GPT-2. Use a prompt of your choice and set the `max_length` to 100. Analyze the output and discuss any interesting patterns or unexpected results you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "creative_prompt = \"The robot woke up and realized it had emotions\"\n",
    "story = generate_text(creative_prompt, max_length=100)\n",
    "print(story)\n",
    "\n",
    "# Your analysis here\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Translation\n",
    "\n",
    "Now, let's work on translating text from one language to another using the MarianMT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, src_lang=\"en\", tgt_lang=\"fr\"):\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}\"\n",
    "    model = MarianMTModel.from_pretrained(model_name).to(device)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    translated = model.generate(**inputs)\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "# Test the function\n",
    "text_to_translate = \"Hello, how are you?\"\n",
    "translated_text = translate_text(text_to_translate)\n",
    "print(f\"Original: {text_to_translate}\")\n",
    "print(f\"Translated: {translated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Multi-language Translation\n",
    "Translate a sentence of your choice into three different languages. Then, translate each result back to English. Discuss any changes in meaning or nuances that occurred during the translation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "original_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "languages = [\"fr\", \"de\", \"es\"]\n",
    "\n",
    "for lang in languages:\n",
    "    translated = translate_text(original_sentence, \"en\", lang)\n",
    "    back_translated = translate_text(translated, lang, \"en\")\n",
    "    print(f\"{lang.upper()}: {translated}\")\n",
    "    print(f\"Back to English: {back_translated}\\n\")\n",
    "\n",
    "# Your analysis here\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Generation with Stable Diffusion\n",
    "\n",
    "Let's explore image generation using the Stable Diffusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(prompt, output_path=\"generated_image.png\"):\n",
    "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(device)\n",
    "    \n",
    "    image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "    image.save(output_path)\n",
    "    display(image)\n",
    "\n",
    "# Test the function\n",
    "image_prompt = \"A futuristic city with flying cars\"\n",
    "generate_image(image_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Creative Image Generation\n",
    "Generate three different images using creative prompts of your choice. For each image, describe the prompt you used and analyze how well the generated image matches your intention. Discuss any unexpected or interesting elements in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "prompts = [\n",
    "    \"A steampunk-inspired coffee machine\",\n",
    "    \"An underwater library with merfolk readers\",\n",
    "    \"A treehouse skyscraper in a futuristic forest\"\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"Prompt {i+1}: {prompt}\")\n",
    "    generate_image(prompt, f\"image_{i+1}.png\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Your analysis here\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Audio Generation and Transcription\n",
    "\n",
    "Finally, let's work with audio generation and transcription using TTS and Whisper models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(text, output_path=\"output.wav\"):\n",
    "    tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=True, gpu=USE_CUDA)\n",
    "    tts.tts_to_file(text=text, file_path=output_path)\n",
    "    display(Audio(output_path))\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Test the functions\n",
    "text_to_speak = \"Hello, this is a test of text-to-speech conversion.\"\n",
    "generate_audio(text_to_speak)\n",
    "\n",
    "transcribed_text = transcribe_audio(\"output.wav\")\n",
    "print(\"Transcribed Text:\")\n",
    "print(transcribed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Audio Chain\n",
    "Create a chain of operations: \n",
    "1. Generate text using GPT-2\n",
    "2. Convert that text to speech\n",
    "3. Transcribe the generated audio back to text\n",
    "\n",
    "Compare the original generated text with the final transcription. Discuss any differences and potential reasons for these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "original_prompt = \"The future of artificial intelligence is\"\n",
    "generated_text = generate_text(original_prompt, max_length=50)\n",
    "print(\"Original Generated Text:\")\n",
    "print(generated_text)\n",
    "\n",
    "generate_audio(generated_text, \"chain_output.wav\")\n",
    "\n",
    "transcribed_text = transcribe_audio(\"chain_output.wav\")\n",
    "print(\"\\nTranscribed Text:\")\n",
    "print(transcribed_text)\n",
    "\n",
    "# Your analysis here\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations on completing this introduction to Generative AI using HuggingFace tools! In this homework, you've explored text generation, translation, image generation, and audio processing. These are fundamental tasks in the field of GenAI, and understanding how they work is crucial for developing more complex applications.\n",
    "\n",
    "### Final Questions:\n",
    "1. What was the most surprising or interesting result you encountered in any of the exercises?\n",
    "2. How do you think these GenAI technologies could be applied in real-world scenarios?\n",
    "3. What ethical considerations should be taken into account when using these technologies?\n",
    "\n",
    "Please write your thoughts on these questions below:\n",
    "\n",
    "Your reflections here:\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
