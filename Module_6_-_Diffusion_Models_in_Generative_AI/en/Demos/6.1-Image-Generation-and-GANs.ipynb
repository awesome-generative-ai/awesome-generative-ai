{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSOnt6mXiyPS"
      },
      "source": [
        "# Module 6: Image Generation with Duffusion Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUq3nSkC49X0",
        "outputId": "84dc68c8-57df-428d-f040-1befe97d4ca4"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq torchview einops matplotlib ipywidgets numpy opencv_python PyYAML torch torchvision tqdm imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSkfKYnBNJ_E"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGJYwx2qkAcb"
      },
      "source": [
        "# 6.1 Images and Convolutions - a recap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFLFuAq1Tk_C"
      },
      "source": [
        "# Understanding Transpose Convolution\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Transpose convolution, also known as fractionally strided convolution or deconvolution (although this last term is mathematically incorrect), is a crucial operation in many deep learning architectures, particularly in tasks involving upsampling, such as image segmentation and generative models.\n",
        "\n",
        "![Diagram: Standard Convolution vs Transpose Convolution]\n",
        "\n",
        "\n",
        "## Basic Concept\n",
        "\n",
        "While standard convolution typically reduces the spatial dimensions of its input, transpose convolution does the opposite - it increases the spatial dimensions. This makes it particularly useful for tasks that require expanding the spatial resolution of features.\n",
        "\n",
        "### Key Points:\n",
        "\n",
        "1. Transpose convolution is not the mathematical inverse of convolution.\n",
        "2. It's a learnable upsampling technique.\n",
        "3. It's often used in the decoder part of autoencoder architectures.\n",
        "\n",
        "## How Transpose Convolution Works\n",
        "\n",
        "Let's break down the process step-by-step:\n",
        "\n",
        "1. **Input**: Start with a smaller input feature map.\n",
        "   \n",
        "   ![Input Feature Map]\n",
        "   (Show a small 2x2 grid with values, e.g., [[1, 2], [3, 4]])\n",
        "\n",
        "2. **Kernel**: Define a learnable kernel (also called filter or weight matrix).\n",
        "   \n",
        "   ![Kernel]\n",
        "   (Show a 2x2 grid with values, e.g., [[1, 2], [3, 4]])\n",
        "\n",
        "3. **Process**:\n",
        "   - For each input element, multiply the entire kernel by that element.\n",
        "   - Place the result in the output, with the top-left corner aligned with the position of the input element.\n",
        "   - Repeat for all input elements, summing where results overlap.\n",
        "\n",
        "   ![Transpose Convolution Process]\n",
        "   (This should be a series of images showing the step-by-step process of multiplying each input element with the kernel and placing the results in the output)\n",
        "\n",
        "4. **Output**: The result is a larger output feature map.\n",
        "   \n",
        "   ![Output Feature Map]\n",
        "   (Show the final 3x3 grid with the computed values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "5WogOWwcen2-",
        "outputId": "e137c3b7-d57e-4169-92c5-24808204c3e8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define input image and kernel\n",
        "input_image = np.array([\n",
        "    [0, 0, 0, 0, 0],\n",
        "    [0, 1, 2, 3, 0],\n",
        "    [0, 4, 5, 6, 0],\n",
        "    [0, 7, 8, 9, 0],\n",
        "    [0, 0, 0, 0, 0]\n",
        "])\n",
        "\n",
        "kernel = np.array([\n",
        "    [1, 0, -1],\n",
        "    [2, 0, -2],\n",
        "    [1, 0, -1]\n",
        "])\n",
        "\n",
        "# Manual convolution function\n",
        "def convolve2d(image, kernel):\n",
        "    output = np.zeros_like(image)\n",
        "    padded_image = np.pad(image, 1, mode='constant')\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            output[i, j] = np.sum(padded_image[i:i+3, j:j+3] * kernel)\n",
        "    return output\n",
        "\n",
        "# Manual transpose convolution function\n",
        "def transpose_convolve2d(image, kernel):\n",
        "    output = np.zeros((image.shape[0]+2, image.shape[1]+2))\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            output[i:i+3, j:j+3] += image[i, j] * kernel\n",
        "    return output\n",
        "\n",
        "# Perform convolution and transpose convolution\n",
        "conv_output = convolve2d(input_image, kernel)\n",
        "trans_conv_output = transpose_convolve2d(input_image, kernel)\n",
        "\n",
        "# Visualization function\n",
        "def visualize(title, images):\n",
        "    fig, axs = plt.subplots(1, len(images), figsize=(20, 5))\n",
        "    fig.suptitle(title)\n",
        "\n",
        "    for i, (name, img) in enumerate(images.items()):\n",
        "        im = axs[i].imshow(img, cmap='viridis')\n",
        "        axs[i].set_title(name)\n",
        "        axs[i].axis('off')\n",
        "        plt.colorbar(im, ax=axs[i])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize results\n",
        "visualize(\"Convolution and Transpose Convolution\", {\n",
        "    \"Input\": input_image,\n",
        "    \"Kernel\": kernel,\n",
        "    \"Convolution Output\": conv_output,\n",
        "    \"Transpose Convolution Output\": trans_conv_output\n",
        "})\n",
        "\n",
        "# Print shapes\n",
        "print(\"Input shape:\", input_image.shape)\n",
        "print(\"Kernel shape:\", kernel.shape)\n",
        "print(\"Convolution output shape:\", conv_output.shape)\n",
        "print(\"Transpose convolution output shape:\", trans_conv_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dGBuxWU7ej8t",
        "outputId": "5d13ea54-dadd-47d3-c9e4-8cb97245614e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a smaller input image for clearer visualization\n",
        "input_image = np.array([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "\n",
        "# Define the kernel (also called the filter or weight matrix)\n",
        "kernel = np.array([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "\n",
        "def detailed_transpose_convolve2d(image, kernel):\n",
        "    # Create an output array with dimensions increased by 1 in each direction\n",
        "    output = np.zeros((image.shape[0]+1, image.shape[1]+1))\n",
        "    steps = []\n",
        "\n",
        "    # Iterate over each element in the input image\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            # Create a temporary array for this step\n",
        "            step = np.zeros_like(output)\n",
        "            # Multiply the current input element by the entire kernel\n",
        "            multiplied_kernel = image[i, j] * kernel\n",
        "            # Place the result in the appropriate position\n",
        "            step[i:i+2, j:j+2] = multiplied_kernel\n",
        "            # Add this step to the output\n",
        "            output += step\n",
        "            # Store intermediate steps for visualization\n",
        "            steps.append((f\"Input[{i},{j}] = {image[i,j]}\", multiplied_kernel))\n",
        "            steps.append((f\"Step {i}-{j}\", step.copy()))\n",
        "\n",
        "    # Add the final output to the steps\n",
        "    steps.append((\"Final Output\", output))\n",
        "    return output, steps\n",
        "\n",
        "# Perform transpose convolution\n",
        "trans_conv_output, steps = detailed_transpose_convolve2d(input_image, kernel)\n",
        "\n",
        "def visualize_steps(title, steps):\n",
        "    n_steps = len(steps)\n",
        "    # Create a figure with subplots for each step\n",
        "    fig, axs = plt.subplots(1, n_steps, figsize=(6*n_steps, 6))\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "\n",
        "    # Iterate over each step\n",
        "    for i, (name, img) in enumerate(steps):\n",
        "        # Display the image using a colormap\n",
        "        im = axs[i].imshow(img, cmap='viridis')\n",
        "        axs[i].set_title(name, fontsize=14)\n",
        "        axs[i].axis('off')\n",
        "        # Add a colorbar to show the scale\n",
        "        plt.colorbar(im, ax=axs[i], fraction=0.046, pad=0.04)\n",
        "\n",
        "        # Add text annotations for the values\n",
        "        for (j,k), value in np.ndenumerate(img):\n",
        "            axs[i].text(k, j, f'{value:.1f}', ha='center', va='center',\n",
        "                        color='white' if value > np.mean(img) else 'black',\n",
        "                        fontweight='bold', fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize input and kernel\n",
        "visualize_steps(\"Input and Kernel\", [(\"Input\", input_image), (\"Kernel\", kernel)])\n",
        "\n",
        "# Visualize transpose convolution steps\n",
        "visualize_steps(\"Transpose Convolution Steps\", steps)\n",
        "\n",
        "# Print shapes and provide explanations\n",
        "print(\"Input shape:\", input_image.shape)\n",
        "print(\"Explanation: This is a 2x2 input image.\")\n",
        "print(\"\\nKernel shape:\", kernel.shape)\n",
        "print(\"Explanation: This is a 2x2 kernel used for the transpose convolution.\")\n",
        "print(\"\\nTranspose convolution output shape:\", trans_conv_output.shape)\n",
        "print(\"Explanation: The output is larger (3x3) due to the nature of transpose convolution.\")\n",
        "\n",
        "# Provide a detailed explanation of the process\n",
        "print(\"\\nDetailed Explanation of Transpose Convolution:\")\n",
        "print(\"1. We start with a 2x2 input and a 2x2 kernel.\")\n",
        "print(\"2. For each input pixel, we multiply the entire kernel by that pixel's value.\")\n",
        "print(\"3. We then place this multiplied kernel in the output, with its top-left corner aligned with the position of the input pixel.\")\n",
        "print(\"4. We do this for all input pixels, summing the results where they overlap.\")\n",
        "print(\"5. This process naturally results in an output that is larger than the input (3x3 in this case).\")\n",
        "print(\"6. The expansion of the input and the overlapping summations allow the transpose convolution to 'learn' how to upsample or increase the spatial dimensions of the input.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp1g4x9rkFJY"
      },
      "source": [
        "## Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-pqEu23-8W7",
        "outputId": "bf20dcd5-d349-4a81-de33-4151d593cb9a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "lr = 0.0005\n",
        "nz = 100  # size of the latent z vector\n",
        "num_epochs = 10\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5Yy79QL-88Y"
      },
      "source": [
        "#### A simple GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPV36RPxOCmI"
      },
      "outputs": [],
      "source": [
        "# !rm -rf ./gan_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPu31MNojR9E",
        "outputId": "ec45f16b-742e-4f7b-8997-ea94f2ac1def"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "lr = 0.0002\n",
        "nz = 100  # size of the latent z vector\n",
        "num_epochs = 10  # Increased for better visualization\n",
        "ngf = 64  # number of generator filters\n",
        "ndf = 64  # number of discriminator filters\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(nz, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1, 1, 28, 28)\n",
        "\n",
        "# Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(28*28, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x.view(-1, 28*28))\n",
        "\n",
        "# Initialize models\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# Loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Function to generate and save images\n",
        "def save_generator_output(G, fixed_noise, epoch, output_dir):\n",
        "    G.eval()\n",
        "    fake_images = G(fixed_noise)\n",
        "    fake_images = fake_images.view(-1, 28, 28)\n",
        "    fake_images = fake_images.detach().cpu().numpy()\n",
        "\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(5, 5))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(fake_images[i], cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Epoch {epoch}\")\n",
        "    plt.savefig(f\"{output_dir}/epoch_{epoch}.png\")\n",
        "    plt.close()\n",
        "    G.train()\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"gan_output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Fixed noise for visualization\n",
        "fixed_noise = torch.randn(16, nz, device=device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "        # Update discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        real_imgs = imgs.to(device)\n",
        "        b_size = real_imgs.size(0)\n",
        "        label_real = torch.full((b_size,), 1., device=device)\n",
        "        label_fake = torch.full((b_size,), 0., device=device)\n",
        "\n",
        "        output = D(real_imgs).view(-1)\n",
        "        lossD_real = criterion(output, label_real)\n",
        "        lossD_real.backward()\n",
        "\n",
        "        noise = torch.randn(b_size, nz, device=device)\n",
        "        fake_imgs = G(noise)\n",
        "        output = D(fake_imgs.detach()).view(-1)\n",
        "        lossD_fake = criterion(output, label_fake)\n",
        "        lossD_fake.backward()\n",
        "\n",
        "        optimizerD.step()\n",
        "        optimizerD.zero_grad()\n",
        "\n",
        "        # Update generator: maximize log(D(G(z)))\n",
        "        output = D(fake_imgs).view(-1)\n",
        "        lossG = criterion(output, label_real)\n",
        "        lossG.backward()\n",
        "\n",
        "        optimizerG.step()\n",
        "        optimizerG.zero_grad()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch {i}/{len(train_loader)} \\\n",
        "                  Loss D: {lossD_real + lossD_fake:.4f}, loss G: {lossG:.4f}\")\n",
        "\n",
        "    # Save generated images\n",
        "    save_generator_output(G, fixed_noise, epoch, output_dir)\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# Create GIF\n",
        "images = []\n",
        "for epoch in range(num_epochs):\n",
        "    images.append(imageio.imread(f\"{output_dir}/epoch_{epoch}.png\"))\n",
        "imageio.mimsave(f\"{output_dir}/gan_training.gif\", images, duration=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "XqGPcfLQMgW7",
        "outputId": "5c3bca0f-6622-4fd0-b019-3d4d87d04c00"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "\n",
        "# Get list of image files\n",
        "import glob\n",
        "image_files = sorted(glob.glob('gan_output/epoch_*.png'))\n",
        "\n",
        "# Function to encode images to base64\n",
        "def image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# Create HTML with all images\n",
        "images_base64 = [image_to_base64(image) for image in image_files]\n",
        "images_html = ''.join([f'<img src=\"data:image/png;base64,{img}\" style=\"display:none;\">' for img in images_base64])\n",
        "\n",
        "# JavaScript to handle animation\n",
        "js_animation = \"\"\"\n",
        "<script>\n",
        "var images = document.querySelectorAll(\"img\");\n",
        "var index = 0;\n",
        "setInterval(function() {\n",
        "    images[index].style.display = \"none\";\n",
        "    index = (index + 1) % images.length;\n",
        "    images[index].style.display = \"block\";\n",
        "}, 500);  // Change image every 500ms\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Combine HTML and JavaScript\n",
        "animation_html = f\"\"\"\n",
        "<div style=\"width:250px; margin:auto;\">\n",
        "    {images_html}\n",
        "    {js_animation}\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# Display the animation\n",
        "display(HTML(animation_html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utKrbCFR64qC"
      },
      "source": [
        "#### Generating Samples with the simple GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "v4C4yy0qjTEK",
        "outputId": "1000e37d-e8cc-4924-c432-77cd2c79a549"
      },
      "outputs": [],
      "source": [
        "# Inference: Generate new images\n",
        "G.eval()  # Set the generator to evaluation mode\n",
        "\n",
        "# Generate a batch of new images\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(16, nz, device=device)  # Generate 16 random noise vectors\n",
        "    fake_imgs = G(noise).cpu()\n",
        "\n",
        "# Function to show images\n",
        "def show_images(images, nrow=4):\n",
        "    images = (images + 1) / 2  # Rescale from [-1, 1] to [0, 1]\n",
        "    grid = np.transpose(images.numpy(), (0, 2, 3, 1))\n",
        "    fig, axes = plt.subplots(nrow, nrow, figsize=(10, 10))\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.imshow(grid[i, :, :, 0], cmap='gray')\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display the generated images\n",
        "show_images(fake_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kadZb6ynF9WZ"
      },
      "source": [
        "### Improving our GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlDZsT45F5aC",
        "outputId": "7f025983-058a-47b8-96f9-6275949f0767"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "lr = 0.0002\n",
        "nz = 100  # size of the latent z vector\n",
        "num_epochs = 10  # Increased for better visualization\n",
        "ngf = 64  # number of generator filters\n",
        "ndf = 64  # number of discriminator filters\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(nz, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1, 1, 28, 28)\n",
        "\n",
        "# Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(28*28, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x.view(-1, 28*28))\n",
        "\n",
        "# Initialize models\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# Loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(G.parameters(), lr=2*lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Function to generate and save images\n",
        "def save_generator_output(G, fixed_noise, epoch, output_dir):\n",
        "    G.eval()\n",
        "    fake_images = G(fixed_noise)\n",
        "    fake_images = fake_images.view(-1, 28, 28)\n",
        "    fake_images = fake_images.detach().cpu().numpy()\n",
        "\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(5, 5))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(fake_images[i], cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Epoch {epoch}\")\n",
        "    plt.savefig(f\"{output_dir}/epoch_{epoch}.png\")\n",
        "    plt.close()\n",
        "    G.train()\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"improved_gan_output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Fixed noise for visualization\n",
        "fixed_noise = torch.randn(16, nz, device=device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "        # Update discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        real_imgs = imgs.to(device)\n",
        "        b_size = real_imgs.size(0)\n",
        "        label_real = torch.full((b_size,), 0.9, device=device)\n",
        "        label_fake = torch.full((b_size,), 0., device=device)\n",
        "\n",
        "        output = D(real_imgs).view(-1)\n",
        "        lossD_real = criterion(output, label_real)\n",
        "        lossD_real.backward()\n",
        "\n",
        "        noise = torch.randn(b_size, nz, device=device)\n",
        "        fake_imgs = G(noise)\n",
        "        output = D(fake_imgs.detach()).view(-1)\n",
        "        lossD_fake = criterion(output, label_fake)\n",
        "        lossD_fake.backward()\n",
        "\n",
        "        optimizerD.step()\n",
        "        optimizerD.zero_grad()\n",
        "\n",
        "        # Update generator: maximize log(D(G(z)))\n",
        "        output = D(fake_imgs).view(-1)\n",
        "        lossG = criterion(output, label_real)\n",
        "        lossG.backward()\n",
        "\n",
        "        optimizerG.step()\n",
        "        optimizerG.zero_grad()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch {i}/{len(train_loader)} \\\n",
        "                  Loss D: {lossD_real + lossD_fake:.4f}, loss G: {lossG:.4f}\")\n",
        "\n",
        "    # Save generated images\n",
        "    save_generator_output(G, fixed_noise, epoch, output_dir)\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# Create GIF\n",
        "images = []\n",
        "for epoch in range(num_epochs):\n",
        "    images.append(imageio.imread(f\"{output_dir}/epoch_{epoch}.png\"))\n",
        "imageio.mimsave(f\"{output_dir}/gan_training.gif\", images, duration=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "ubnLqiuKSWdI",
        "outputId": "14e53d7d-2706-44bb-cdb2-73e76a22ceba"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "\n",
        "# Get list of image files\n",
        "import glob\n",
        "image_files = sorted(glob.glob('improved_gan_output/epoch_*.png'))\n",
        "\n",
        "# Function to encode images to base64\n",
        "def image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# Create HTML with all images\n",
        "images_base64 = [image_to_base64(image) for image in image_files]\n",
        "images_html = ''.join([f'<img src=\"data:image/png;base64,{img}\" style=\"display:none;\">' for img in images_base64])\n",
        "\n",
        "# JavaScript to handle animation\n",
        "js_animation = \"\"\"\n",
        "<script>\n",
        "var images = document.querySelectorAll(\"img\");\n",
        "var index = 0;\n",
        "setInterval(function() {\n",
        "    images[index].style.display = \"none\";\n",
        "    index = (index + 1) % images.length;\n",
        "    images[index].style.display = \"block\";\n",
        "}, 500);  // Change image every 500ms\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Combine HTML and JavaScript\n",
        "animation_html = f\"\"\"\n",
        "<div style=\"width:250px; margin:auto;\">\n",
        "    {images_html}\n",
        "    {js_animation}\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# Display the animation\n",
        "display(HTML(animation_html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "WH9Ota9_GPp0",
        "outputId": "0783f4e5-08cd-4b45-8f49-4779686b3700"
      },
      "outputs": [],
      "source": [
        "# Inference: Generate new images\n",
        "G.eval()  # Set the generator to evaluation mode\n",
        "\n",
        "# Generate a batch of new images\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(16, nz, device=device)  # Generate 16 random noise vectors\n",
        "    fake_imgs = G(noise).cpu()\n",
        "\n",
        "# Function to show images\n",
        "def show_images(images, nrow=4):\n",
        "    images = (images + 1) / 2  # Rescale from [-1, 1] to [0, 1]\n",
        "    grid = np.transpose(images.numpy(), (0, 2, 3, 1))\n",
        "    fig, axes = plt.subplots(nrow, nrow, figsize=(10, 10))\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.imshow(grid[i, :, :, 0], cmap='gray')\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display the generated images\n",
        "show_images(fake_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66QOsObU8ofV"
      },
      "source": [
        "### Deep Convolution GAN (DCGAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbdUnsXPVKDo",
        "outputId": "d5e5c6be-1a4d-495c-fcc4-ba830c6fca78"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 1024\n",
        "lr = 0.0002\n",
        "nz = 100  # size of the latent z vector\n",
        "num_epochs = 25\n",
        "ngf = 64  # number of generator filters\n",
        "ndf = 64  # number of discriminator filters\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# Create output directory\n",
        "output_dir = \"dcgan_output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "fixed_noise = torch.randn(16, 100, device=device)\n",
        "\n",
        "\n",
        "def save_generator_output(G, fixed_noise, epoch, output_dir):\n",
        "    G.eval()\n",
        "    with torch.no_grad():\n",
        "        # Reshape the noise vector to 4D: (batch_size, channels, 1, 1)\n",
        "        fixed_noise = fixed_noise.view(fixed_noise.size(0), -1, 1, 1)\n",
        "        fake_images = G(fixed_noise)\n",
        "    fake_images = fake_images.detach().cpu()\n",
        "\n",
        "    # Denormalize the images\n",
        "    fake_images = (fake_images + 1) / 2.0  # Rescale from [-1, 1] to [0, 1]\n",
        "    fake_images = fake_images.clamp(0, 1)\n",
        "\n",
        "    # Convert to numpy and transpose for correct display\n",
        "    fake_images = fake_images.numpy().transpose(0, 2, 3, 1)\n",
        "\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(4, 4))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(fake_images[i])\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Epoch {epoch}\")\n",
        "    plt.savefig(f\"{output_dir}/epoch_{epoch}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    G.train()\n",
        "\n",
        "# Generator network (DCGAN)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. 3 x 32 x 32\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.main(x)\n",
        "        return output\n",
        "\n",
        "# Discriminator network (DCGAN)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (3, 32, 32)\n",
        "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 16 x 16\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 8 x 8\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 4 x 4\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1)\n",
        "\n",
        "# Initialize models\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# Loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "        # Update discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        real_imgs = imgs.to(device)\n",
        "        b_size = real_imgs.size(0)\n",
        "        label_real = torch.full((b_size,), 1.0, device=device)  # Use label smoothing for real labels\n",
        "        label_fake = torch.full((b_size,), 0.0, device=device)\n",
        "\n",
        "        # Train with real images\n",
        "        D.zero_grad()\n",
        "        output = D(real_imgs).view(-1)\n",
        "        lossD_real = criterion(output, label_real)\n",
        "        lossD_real.backward()\n",
        "\n",
        "        # Train with fake images\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        fake_imgs = G(noise)\n",
        "        output = D(fake_imgs.detach()).view(-1)\n",
        "        lossD_fake = criterion(output, label_fake)\n",
        "        lossD_fake.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        # Update generator: maximize log(D(G(z)))\n",
        "        G.zero_grad()\n",
        "        label_fake.fill_(0.9)  # Use real labels for generator loss\n",
        "        output = D(fake_imgs).view(-1)\n",
        "        lossG = criterion(output, label_fake)\n",
        "        lossG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Save generated images\n",
        "        save_generator_output(G, fixed_noise, epoch, output_dir)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch {i}/{len(train_loader)} \\\n",
        "                  Loss D: {lossD_real + lossD_fake:.4f}, loss G: {lossG:.4f}\")\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jzdaUyABV75Z",
        "outputId": "40ebb1d5-c3fa-4099-daa8-5a201d4714d1"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "\n",
        "# Get list of image files\n",
        "import glob\n",
        "image_files = sorted(glob.glob('dcgan_output/epoch_*.png'))\n",
        "\n",
        "# Function to encode images to base64\n",
        "def image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# Create HTML with all images\n",
        "images_base64 = [image_to_base64(image) for image in image_files]\n",
        "images_html = ''.join([f'<img src=\"data:image/png;base64,{img}\" style=\"display:none;\">' for img in images_base64])\n",
        "\n",
        "# JavaScript to handle animation\n",
        "js_animation = \"\"\"\n",
        "<script>\n",
        "var images = document.querySelectorAll(\"img\");\n",
        "var index = 0;\n",
        "setInterval(function() {\n",
        "    images[index].style.display = \"none\";\n",
        "    index = (index + 1) % images.length;\n",
        "    images[index].style.display = \"block\";\n",
        "}, 500);  // Change image every 500ms\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Combine HTML and JavaScript\n",
        "animation_html = f\"\"\"\n",
        "<div style=\"width:250px; margin:auto;\">\n",
        "    {images_html}\n",
        "    {js_animation}\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# Display the animation\n",
        "display(HTML(animation_html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Px2goebCT3v"
      },
      "source": [
        "### NOTE: LAB SOLUTION\n",
        "\n",
        "Improve the DCGAN:\n",
        "\n",
        "### Improving our DCGAN Generator\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "label_real = torch.full((b_size,), 0.9, device=device)\n",
        "batch_size = 128\n",
        "lr = 0.0005\n",
        "optimizerG = optim.Adam(G.parameters(), lr=1.5*lr, betas=(0.5, 0.999))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "NlY8ksJjMT-g",
        "outputId": "f67791c6-990c-41d0-99fc-898347c3c2a8"
      },
      "outputs": [],
      "source": [
        "# Inference: Generate new images\n",
        "G.eval()  # Set the generator to evaluation mode\n",
        "\n",
        "# Generate a batch of new images\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(16, nz, 1, 1, device=device)  # Generate 16 random noise vectors\n",
        "    fake_imgs = G(noise).cpu()\n",
        "\n",
        "# Function to show images\n",
        "def show_images(images, nrow=4):\n",
        "    images = (images + 1) / 2  # Rescale from [-1, 1] to [0, 1]\n",
        "    grid = np.transpose(images.numpy(), (0, 2, 3, 1))\n",
        "    fig, axes = plt.subplots(nrow, nrow, figsize=(10, 10))\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.imshow(grid[i])\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display the generated images\n",
        "show_images(fake_imgs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
